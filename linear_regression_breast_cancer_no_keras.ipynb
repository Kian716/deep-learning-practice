{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_dataset = load_breast_cancer()\n",
    "breast = pd.DataFrame(breast_dataset.data, columns=breast_dataset.feature_names)\n",
    "breast['y'] = breast_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  y  \n",
       "0          0.4601                  0.11890  0  \n",
       "1          0.2750                  0.08902  0  \n",
       "2          0.3613                  0.08758  0  \n",
       "3          0.6638                  0.17300  0  \n",
       "4          0.2364                  0.07678  0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 31) (456, 31)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = breast.iloc[-int(0.2*len(breast)):,:]\n",
    "train_dataset = breast.iloc[:-int(0.2*len(breast)),:]\n",
    "print(test_dataset.shape, train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.convert_to_tensor(test_dataset)\n",
    "X_test = test_dataset[:,:-1]\n",
    "y_test = test_dataset[:,-1]\n",
    "train_dataset = tf.convert_to_tensor(train_dataset)\n",
    "X_train = train_dataset[:,:-1]\n",
    "y_train = train_dataset[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(buffer_size=len(data_arrays))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "data_iter = load_array((train_dataset[:,:-1],train_dataset[:,-1]), batch_size, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16, 30), dtype=float64, numpy=\n",
      "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
      "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
      "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
      "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
      "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
      "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
      "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
      "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
      "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
      "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
      "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
      "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
      "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02],\n",
      "       [2.029e+01, 1.434e+01, 1.351e+02, 1.297e+03, 1.003e-01, 1.328e-01,\n",
      "        1.980e-01, 1.043e-01, 1.809e-01, 5.883e-02, 7.572e-01, 7.813e-01,\n",
      "        5.438e+00, 9.444e+01, 1.149e-02, 2.461e-02, 5.688e-02, 1.885e-02,\n",
      "        1.756e-02, 5.115e-03, 2.254e+01, 1.667e+01, 1.522e+02, 1.575e+03,\n",
      "        1.374e-01, 2.050e-01, 4.000e-01, 1.625e-01, 2.364e-01, 7.678e-02],\n",
      "       [1.142e+01, 2.038e+01, 7.758e+01, 3.861e+02, 1.425e-01, 2.839e-01,\n",
      "        2.414e-01, 1.052e-01, 2.597e-01, 9.744e-02, 4.956e-01, 1.156e+00,\n",
      "        3.445e+00, 2.723e+01, 9.110e-03, 7.458e-02, 5.661e-02, 1.867e-02,\n",
      "        5.963e-02, 9.208e-03, 1.491e+01, 2.650e+01, 9.887e+01, 5.677e+02,\n",
      "        2.098e-01, 8.663e-01, 6.869e-01, 2.575e-01, 6.638e-01, 1.730e-01],\n",
      "       [1.245e+01, 1.570e+01, 8.257e+01, 4.771e+02, 1.278e-01, 1.700e-01,\n",
      "        1.578e-01, 8.089e-02, 2.087e-01, 7.613e-02, 3.345e-01, 8.902e-01,\n",
      "        2.217e+00, 2.719e+01, 7.510e-03, 3.345e-02, 3.672e-02, 1.137e-02,\n",
      "        2.165e-02, 5.082e-03, 1.547e+01, 2.375e+01, 1.034e+02, 7.416e+02,\n",
      "        1.791e-01, 5.249e-01, 5.355e-01, 1.741e-01, 3.985e-01, 1.244e-01],\n",
      "       [1.371e+01, 2.083e+01, 9.020e+01, 5.779e+02, 1.189e-01, 1.645e-01,\n",
      "        9.366e-02, 5.985e-02, 2.196e-01, 7.451e-02, 5.835e-01, 1.377e+00,\n",
      "        3.856e+00, 5.096e+01, 8.805e-03, 3.029e-02, 2.488e-02, 1.448e-02,\n",
      "        1.486e-02, 5.412e-03, 1.706e+01, 2.814e+01, 1.106e+02, 8.970e+02,\n",
      "        1.654e-01, 3.682e-01, 2.678e-01, 1.556e-01, 3.196e-01, 1.151e-01],\n",
      "       [1.825e+01, 1.998e+01, 1.196e+02, 1.040e+03, 9.463e-02, 1.090e-01,\n",
      "        1.127e-01, 7.400e-02, 1.794e-01, 5.742e-02, 4.467e-01, 7.732e-01,\n",
      "        3.180e+00, 5.391e+01, 4.314e-03, 1.382e-02, 2.254e-02, 1.039e-02,\n",
      "        1.369e-02, 2.179e-03, 2.288e+01, 2.766e+01, 1.532e+02, 1.606e+03,\n",
      "        1.442e-01, 2.576e-01, 3.784e-01, 1.932e-01, 3.063e-01, 8.368e-02],\n",
      "       [1.300e+01, 2.182e+01, 8.750e+01, 5.198e+02, 1.273e-01, 1.932e-01,\n",
      "        1.859e-01, 9.353e-02, 2.350e-01, 7.389e-02, 3.063e-01, 1.002e+00,\n",
      "        2.406e+00, 2.432e+01, 5.731e-03, 3.502e-02, 3.553e-02, 1.226e-02,\n",
      "        2.143e-02, 3.749e-03, 1.549e+01, 3.073e+01, 1.062e+02, 7.393e+02,\n",
      "        1.703e-01, 5.401e-01, 5.390e-01, 2.060e-01, 4.378e-01, 1.072e-01],\n",
      "       [1.246e+01, 2.404e+01, 8.397e+01, 4.759e+02, 1.186e-01, 2.396e-01,\n",
      "        2.273e-01, 8.543e-02, 2.030e-01, 8.243e-02, 2.976e-01, 1.599e+00,\n",
      "        2.039e+00, 2.394e+01, 7.149e-03, 7.217e-02, 7.743e-02, 1.432e-02,\n",
      "        1.789e-02, 1.008e-02, 1.509e+01, 4.068e+01, 9.765e+01, 7.114e+02,\n",
      "        1.853e-01, 1.058e+00, 1.105e+00, 2.210e-01, 4.366e-01, 2.075e-01],\n",
      "       [1.578e+01, 1.789e+01, 1.036e+02, 7.810e+02, 9.710e-02, 1.292e-01,\n",
      "        9.954e-02, 6.606e-02, 1.842e-01, 6.082e-02, 5.058e-01, 9.849e-01,\n",
      "        3.564e+00, 5.416e+01, 5.771e-03, 4.061e-02, 2.791e-02, 1.282e-02,\n",
      "        2.008e-02, 4.144e-03, 2.042e+01, 2.728e+01, 1.365e+02, 1.299e+03,\n",
      "        1.396e-01, 5.609e-01, 3.965e-01, 1.810e-01, 3.792e-01, 1.048e-01],\n",
      "       [1.917e+01, 2.480e+01, 1.324e+02, 1.123e+03, 9.740e-02, 2.458e-01,\n",
      "        2.065e-01, 1.118e-01, 2.397e-01, 7.800e-02, 9.555e-01, 3.568e+00,\n",
      "        1.107e+01, 1.162e+02, 3.139e-03, 8.297e-02, 8.890e-02, 4.090e-02,\n",
      "        4.484e-02, 1.284e-02, 2.096e+01, 2.994e+01, 1.517e+02, 1.332e+03,\n",
      "        1.037e-01, 3.903e-01, 3.639e-01, 1.767e-01, 3.176e-01, 1.023e-01],\n",
      "       [1.602e+01, 2.324e+01, 1.027e+02, 7.978e+02, 8.206e-02, 6.669e-02,\n",
      "        3.299e-02, 3.323e-02, 1.528e-01, 5.697e-02, 3.795e-01, 1.187e+00,\n",
      "        2.466e+00, 4.051e+01, 4.029e-03, 9.269e-03, 1.101e-02, 7.591e-03,\n",
      "        1.460e-02, 3.042e-03, 1.919e+01, 3.388e+01, 1.238e+02, 1.150e+03,\n",
      "        1.181e-01, 1.551e-01, 1.459e-01, 9.975e-02, 2.948e-01, 8.452e-02],\n",
      "       [1.585e+01, 2.395e+01, 1.037e+02, 7.827e+02, 8.401e-02, 1.002e-01,\n",
      "        9.938e-02, 5.364e-02, 1.847e-01, 5.338e-02, 4.033e-01, 1.078e+00,\n",
      "        2.903e+00, 3.658e+01, 9.769e-03, 3.126e-02, 5.051e-02, 1.992e-02,\n",
      "        2.981e-02, 3.002e-03, 1.684e+01, 2.766e+01, 1.120e+02, 8.765e+02,\n",
      "        1.131e-01, 1.924e-01, 2.322e-01, 1.119e-01, 2.809e-01, 6.287e-02],\n",
      "       [1.454e+01, 2.754e+01, 9.673e+01, 6.588e+02, 1.139e-01, 1.595e-01,\n",
      "        1.639e-01, 7.364e-02, 2.303e-01, 7.077e-02, 3.700e-01, 1.033e+00,\n",
      "        2.879e+00, 3.255e+01, 5.607e-03, 4.240e-02, 4.741e-02, 1.090e-02,\n",
      "        1.857e-02, 5.466e-03, 1.746e+01, 3.713e+01, 1.241e+02, 9.432e+02,\n",
      "        1.678e-01, 6.577e-01, 7.026e-01, 1.712e-01, 4.218e-01, 1.341e-01],\n",
      "       [1.468e+01, 2.013e+01, 9.474e+01, 6.845e+02, 9.867e-02, 7.200e-02,\n",
      "        7.395e-02, 5.259e-02, 1.586e-01, 5.922e-02, 4.727e-01, 1.240e+00,\n",
      "        3.195e+00, 4.540e+01, 5.718e-03, 1.162e-02, 1.998e-02, 1.109e-02,\n",
      "        1.410e-02, 2.085e-03, 1.907e+01, 3.088e+01, 1.234e+02, 1.138e+03,\n",
      "        1.464e-01, 1.871e-01, 2.914e-01, 1.609e-01, 3.029e-01, 8.216e-02]])>, <tf.Tensor: shape=(16,), dtype=float64, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])>)\n"
     ]
    }
   ],
   "source": [
    "for data in data_iter:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "W = tf.Variable(tf.zeros((30,1)), trainable=True)\n",
    "b =tf.Variable(tf.zeros(1), trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def net(X, W, b):\n",
    "    res = tf.matmul(tf.cast(X, dtype=W.dtype), W)+b\n",
    "    res = 1/(1+tf.exp(-res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "def loss(y_hat,y):\n",
    "    y = tf.cast(y, dtype=y_hat.dtype)\n",
    "    y = tf.reshape(y, y_hat.shape) \n",
    "    l = -y*tf.math.log(y_hat)-(1-y)*tf.math.log(1-y_hat)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化算法\n",
    "def sgd(params, grads, lr, batch_size):\n",
    "    for param, grad in zip(params, grads):\n",
    "        param.assign_sub(lr*grad/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_pred, y):\n",
    "    ones = tf.ones_like(y_pred)\n",
    "    zeros = tf.zeros_like(y_pred)\n",
    "    output = tf.where(y_pred > 0.5 , ones, zeros)\n",
    "    y = tf.reshape(y, output.shape)\n",
    "    res = tf.reduce_sum(tf.where(y == tf.cast(output, dtype=y.dtype), ones, zeros))/y.shape[0]\n",
    "    return res.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, train_loss:0.5787349343299866, train_acc:0.7609649300575256, test_loss:0.5272122025489807, test_acc:0.8318583965301514\n",
      "epoch:2, train_loss:0.48076796531677246, train_acc:0.8377193212509155, test_loss:0.5559106469154358, test_acc:0.7345132827758789\n",
      "epoch:3, train_loss:0.4356544315814972, train_acc:0.8991228342056274, test_loss:0.44666680693626404, test_acc:0.8938053250312805\n",
      "epoch:4, train_loss:0.4431581199169159, train_acc:0.8355262875556946, test_loss:0.3857197165489197, test_acc:0.9203540086746216\n",
      "epoch:5, train_loss:0.40765273571014404, train_acc:0.8662280440330505, test_loss:0.3692420423030853, test_acc:0.9292035102844238\n",
      "epoch:6, train_loss:0.3808024823665619, train_acc:0.8947368264198303, test_loss:0.361583411693573, test_acc:0.9380530714988708\n",
      "epoch:7, train_loss:0.3713128864765167, train_acc:0.8947368264198303, test_loss:0.3448375165462494, test_acc:0.9380530714988708\n",
      "epoch:8, train_loss:0.3611350953578949, train_acc:0.8947368264198303, test_loss:0.3333091139793396, test_acc:0.9380530714988708\n",
      "epoch:9, train_loss:0.3453652262687683, train_acc:0.9035087823867798, test_loss:0.3333792984485626, test_acc:0.9292035102844238\n",
      "epoch:10, train_loss:0.34440430998802185, train_acc:0.8947368264198303, test_loss:0.31446585059165955, test_acc:0.9380530714988708\n"
     ]
    }
   ],
   "source": [
    "lr = 0.00001\n",
    "batch_size = 16\n",
    "for epoch in range(10):\n",
    "    for X, y in data_iter:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_hat = net(tf.cast(X,dtype=W.dtype), W, b)\n",
    "            l = loss(y_hat, y)\n",
    "        dW, db = tape.gradient(l, [W,b])\n",
    "        # print(dW, db)\n",
    "        sgd([W, b],[dW, db], lr, batch_size)\n",
    "    train_loss = loss(net(X_train, W, b), y_train)\n",
    "    train_acc = evaluate(net(X_train, W, b), y_train)\n",
    "    test_loss = loss(net(X_test, W, b), y_test)\n",
    "    test_acc = evaluate(net(X_test, W, b), y_test)\n",
    "    print('epoch:{}, train_loss:{}, train_acc:{}, test_loss:{}, test_acc:{}'\\\n",
    "        .format(epoch+1, float(tf.reduce_mean(train_loss)), train_acc,\n",
    "                         float(tf.reduce_mean(test_loss)), test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loc_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb210df15ccbc807886e443738f30d2650868bc41b7c3ce172e2655787add45a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
